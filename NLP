#https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners#Training
from datasets import Dataset,DatasetDict

ds = Dataset.from_pandas(df)
model_nm = 'microsoft/deberta-v3-small'
from transformers import AutoModelForSequenceClassification,AutoTokenizer
# convert data into tokens, a token is the specific form that NLP requires, every pre-trained model has its own way to convert a sentence into tokens(vocabulary) 
tokz = AutoTokenizer.from_pretrained(model_nm)

tokz.tokenize("G'day folks, I'm Jeremy from fast.ai!")
def tok_func(x): return tokz(x["input"])
tok_ds = ds.map(tok_func, batched=True)
row = tok_ds[0]
row['input'], row['input_ids']
tokz.vocab['‚ñÅof']

tok_ds = tok_ds.rename_columns({'score':'labels'})
# transformer requires labels as the name of the target

eval_df = pd.read_csv(path/'test.csv')
eval_df.describe()

dds = tok_ds.train_test_split(0.25, seed=42)
dds
# randomly generate training set and validation set in transformer, may not be a good idea for some cases

eval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor
eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)
# .map() this code applys a function (tok_func in this case) for each data

def corr(x,y): return np.corrcoef(x,y)[0][1]
# returns correlation coefficients, we use this as a metric in this case

def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}

from transformers import TrainingArguments,Trainer
bs = 128
epochs = 4
lr = 8e-5
args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,
    evaluation_strategy="epoch", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,
    num_train_epochs=epochs, weight_decay=0.01, report_to='none')

model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)
trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],
                  tokenizer=tokz, compute_metrics=corr_d)
trainer.train();
preds = trainer.predict(eval_ds).predictions.astype(float)
# .predictions shows the prediction result and .astype converts the data type
preds
preds = np.clip(preds, 0, 1)
# force the number higher then 1 be 1 and lower then 0 be 0

import datasets

submission = datasets.Dataset.from_dict({
    'id': eval_ds['id'],
    'score': preds
})

submission.to_csv('submission.csv', index=False)
